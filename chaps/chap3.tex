\section{Methoden zur Berechnung von Ableitungen ($f: \mathbb{R}^n \mapsto \mathbb{R}$)}


\subsection{numerisch / Differenzenquotient}
\label{subsec:numerisch / Differenzenquotient}
Idee: approximiere den Grenzwert
\begin{align*}
\frac{\partial f}{\partial x_i} & = lim_{h\mapsto 0} \frac{f(x_1,\dots,x_n) - f(x_i,\dots,x_n)}{h}\\
 &= lim_{h\mapsto 0} \frac{f(x+h \cdot l_i) - f(x)}{h}
\end{align*}
wobei $l_i$ an der $i$-ten Stelle den Wert 1 und sonst den Wert 0 hat, durch 
$$\frac{\partial f}{\partial x_i}(x) \approx \left[\frac{f(x+e,\tilde h)-f(x)}{\tilde h)}\right]$$
mit \glqq hinreichend kleinem"\ Wert $\tilde h \in R^+$
\\
Vorteil:
\begin{itemize}
	\item einfach zu implementieren
	\item benötigt nur Auswertung für f
\end{itemize}
Nachteil:
\begin{itemize}
	\item $\tilde h$ ist unbekannt, \glqq falsche"\ Wahl von $\tilde h$ kann zu Rundungs-/ Approximationsfehlern führen
	\item Berechnung von $\nabla f$ benötigt $n+1$ Auswertungen der Funktion $f$ - teuer für eine große Anzahl von Variablen
\end{itemize}
\vspace{3cm}
Grafik zur Genauigkeit: Fehler V -förmig (Rundungsfehler und Ungenauigkeit)

\subsection{Analytisches Differenzieren/ per Hand}
Idee: Benutze Standard-Differentationsregeln zum Ableiten einer Funktion, d.h. Kettenregel / Produktregel / Divisionsregel / Summenregel / Winkelfunktionen / Weitere

\noindent Vorteil:
\begin{itemize}
	\item kann sehr effiziente, genaue Ergebnisse liefern
\end{itemize}
Nachteil:
\begin{itemize}
	\item fehleranfällig
	\item z.T. sehr aufwendig, wenn überhaupt möglich
\end{itemize}
Beispielrechnung
$$f:\mathbb{R}^2\mapsto\mathbb{R}, f(x_1,x_2) = \frac{x_2 x_1^2}{sin(x_1)}+cos(x_2)$$

%\begin{align*}
%	\frac{\partial f(x_1,x_2)}{\partial x_1} &= \frac{\partial }{\partial x_1}
%	 = \frac{2x_2x_1}{den}\\	
%\end{align*}
\vspace{3cm}
\subsection{Symbolisches Differenzieren}
Idee: Zerlegung einer Funktion in ihre elementaren Operationen als Berechnungsbaum und anschließende Transformation mittels vorheriger Ableitungsregeln darstellen
Beispiel: $f$ wie zuvor, Grafik: symbolischer Berechnungsbaum von $f$

\vspace{8cm}

wird zu, Grafik:  symbolischer Berechnungsbaum mit 41 Knoten

\vspace{10cm}

Vorteil:
\begin{itemize}
	\item exakte Ableitungen
	\item automatisierbar
	\item nachvollziehbar
	\item (kann effizient sein)
\end{itemize}
Nachteil
\begin{itemize}
	\item speicherintensiv!!
\end{itemize}
typisches Gegenbeispiel (Speelpenning):
$f:\mathbb{R}^n\mapsto\mathbb{R}, f(x) = \prod_{i=1}^n x_i$
Bemerkung: $\prod_{i=1}^n x_i$ taucht z.B. in der Berechnung von Determinanten o.ä. linear Algebra OPs vor.

\subsection{Automatisches/ Algorithmisches Differenzieren}

gegeben: eine mathematische Funktion: $F:\mathbb{R}^n\mapsto\mathbb{R}^m$, welche
\begin{itemize}
	\item hinreichend oft differenzierbar ist
	\item durch einen endlichen \glqq Straight-Line" Code beschrieben werden kann, d.h. keine (unendliche) Rekursion und Verzweigungen (if-branches,\dots) enthält
\end{itemize}
Mit anderen Worten $F:U\subseteq \mathbb{R}^n\mapsto\mathbb{R}^m, F(x) = y$ ist gegeben durch eine sogenannte Evaluation Procedure
\begin{align*}
	v_{i-n}= x_i & i = 1,\dots,n && Eingabe\\
	v_i = \ \varphi_i(v_j) & i = 1,\dots,l && Auswertung\\
	y_{m-i}& i = m-1,\dots,0 && Ausgabe
\end{align*}
wobei $x \in \mathbb{R}$ die unabhängigegen, $y \in \mathbb{R}^m$ abhängigen, $v_i \in \mathbb{R}$ Zwischenvariablen und 
$$\varphi \in \Phi = \{\pm, cos, sin, \sqrt{\cdot}, Exp, Log \dots \}$$
hinreichend oft differenzierbare Elementarfkt. (über U) sind.

\vspace{\baselineskip}
\noindent Ziel: 

effiziente numerische Bestimmung von Ableitungsinformationen der Funktion bezüglich ihrer Ausgabe $y=F(x)$ und Eingabe $x \in \mathbb{R}^n$
\vspace{\baselineskip}

\noindent Bemerkung:

Die Zwischenvariablen $v_i$ in der Eval. Proc. können nach ihrer Berechnungsvorschrift sortiert werden und induzieren einen \glqq Computational DAG", in welchem jede Zwischenvariable durch einen Knoten repräsentiert wird. Eine Kante existiert wenn eine solche Variable direkt von einer Anderen abhängt.
$v_i = \varphi(v_j)_{j \prec i}$ ist eine Kurzschreibweise für den Funktionswert der entsprechenden Elementarfkt. $\varphi_i$ zur Auswertung von $v_i$, die von den vorher berechneten Werten ($(v_j)_{j \prec i}$) direkt abhängt.

\vspace{\baselineskip}

\noindent Forward Mode

Ausgehend von der Evaluation Procedure kann man eine erweiterte/ extended  Eval. Proc. angeben, welche sowohl $y=F(x)$ als auch $\dot{y}=F'(x)\dot{x}$ für $\dot{x}\in \mathbb{R}$ berechnet.

\begin{tabular}{| L | L | L |}
	\hline
	v_{i-n} = x_i & i=1,\dots ,n& Eingabe\\
	\dot{v}_{i-n} = \dot{x}_i & &\\
	\hline
	v_i = \ \varphi_i(v_j) & i = 1,\dots,l & Auswertung\\ 
	\dot{v}_i = \sum_{j \prec i} \frac{\partial}{\partial v_j}\varphi_i(u_i)\cdot \dot{v}_j & u_i = (v_j)_{j\prec i} &\\
	\hline
	y_{m-i}& i = m-1,\dots,0 & Ausgabe\\
	\dot{y}_{m-i}& &\\
	\hline
\end{tabular}
\newpage
\noindent Beispiel : $f : \mathbb{R}^2\mapsto\mathbb{R}$ wie zuvor gegeben\\

\begin{tabular}{| L | L |}
	\hline
	v_{-1} = x_1& \\
	\dot{v}_{-1} = \dot{x}_1& Eingabe\\
	v_0 = x_2&\\
	\dot{v}_0 = \dot{x}_2&\\
	\hline
	v_1 = v_{-1}^2&\\
	\dot{v}_1 = 2 v_{-1} \cdot \dot{v}_{-1} &\\
	v_2 = v_0 v_1 &\\
	\dot{v}_2 = \dot{v}_0v_1 + v_0\dot{v}_1&\\
	v_3 = sin(v_{-1})&\\
	\dot{v}_3 = cos(v_{-1})\dot{v}_{-1} & Auswertung\\
	v_4 = v_2 / v_3&\\
	\dot{v}_4 = 1\cdot \frac{\dot{v}_2}{v_3^3} + \frac{-v_2}{v_3^2}\cdot \dot{v}_3&\\
	v_5 = cos(v_0)&\\
	\dot{v}_5 = -sin(v_0)\dot{v}_0&\\
	v_6 = v_4 + v_5&\\
	\dot{v}_6 = 1\cdot \dot{v}_4 + 1 \cdot \dot{v}_5&\\
	\hline
	y_1 = v_6&Ausgabe\\
	\dot{y}_1 = \dot{v}_6&\\
	\hline
\end{tabular}
\quad\quad
\begin{tabular} { L }
	V = (0, \dots, 0)\\
	\quad\quad\downarrow \Phi_{-1}\\
	V = (v_{-1},0, \dots, 0)\\
	\quad\quad\downarrow \Phi_0\\
	V = (v_{-1}, v_0,0, \dots)\\
	\quad\quad\downarrow \Phi_1\\
	V = (v_{-1}, v_0, v_{-1}^2,0, \dots)\\
	\quad\quad\downarrow \Phi_2\\
	V = (v_{-1}, v_0, v_{-1}^2, v_{-1}v_0,0, \dots)\\
	\quad\quad\scalebox{1}[2]{\rotatebox{-90}{$\dashrightarrow$}}\\
	\\
	V = (v_{-1}, v_0, \dots, v_4+v_5, 0)\\
	\quad\quad\downarrow \Phi_7\\
	V = (v_{-1}, v_0, \dots, v_4+v_5, v_6)\\
\end{tabular}

\vspace{\baselineskip}

\noindent
\begin{tabular}{L | P{1.2cm}  L}
	\hline
	\text{Grafik: Computational Graph für }f \quad\quad\quad\quad& Tabelle&\text{: part.Ordnung der }v_i\text{'s}\\
	& &\\
	&$\varnothing$ &\prec -1\\
	&$\varnothing$ &\prec 0\\
	&$-1$ &\prec 1\\
	&$0,1$ &\prec 2\\
	&$-1$ &\prec 3\\
	&$2,3$ &\prec 4\\
	&$0$ &\prec 5\\
	&$4,5$ &\prec 6\\
\end{tabular}

\noindent
Begründung:

Der Forward Mode beruht auf der Kettenregel:\\
$$\Phi_2(\Phi_1(x))' = \Phi_2'(\Phi_1(x))\cdot \Phi_1'(x)$$,
welche mehrfach auf die erweiterten Abbildungen $\Phi_i : \tilde{V}\mapsto\tilde{V}$ angewendet wird, wobei $\tilde{V}\subseteq \mathbb{R}^{n+l+m}$ und $V \in \tilde{V}$ der Vektor aller Zwischenvariablen $v_i$, d.h.
$$V=(v_{1-n},\dots, v_0,v_1, \dots , v_l, v_{l+1},\dots, v_{l+,})$$
ist und somit $\Phi_i$ die Ausführung einer Zeile $v_i=\dots$ entspricht.

Mit anderen Worten berechnet die Extended Evaluation Procedure nichts anderes als
$$y=P \Phi_l(\Phi_{l-1}(\dots \Phi_1(Qx))\dots)) \quad \text{und}$$
$$\dot{y} = P \Phi_l'(V_l)\cdot\Phi_{l-1}'(V_{l-1})\cdot\dots\cdot\Phi_1'(V_1)\cdot Q\dot{x} \text{ ,}$$
wobei
$P$ Projektionsmatrix
$$ P =
\begin{bmatrix}
	  0		& \dots	& 0		& 0		& \dots	& 0		& 1	& 		&  \\
	  \vdots& \ddots& \vdots& \vdots& \ddots& \vdots& 	& \ddots&  \\
	  0		& \dots & 0		& 0		& \dots	& 0		&	&		& 1\\
\end{bmatrix}_{(n+l+m)\times m}
$$
$Q$ Prolongationsmatrix
$$ Q= 
\begin{bmatrix}
	1		&		&  \\
			& \ddots&  \\
			&		& 1\\
	0		& \dots	& 0\\
	\vdots	& \ddots& \vdots\\
	0		& \dots & 0\\
	
	0		& \dots	& 0\\
	\vdots	& \ddots& \vdots\\
	0		& \dots & 0	
\end{bmatrix}_{n \times (n+l+m)}
$$
und  $V_{i+1}=\Phi_i(V_i)$ mit $V_{1-n}=Qx$ ist,
in einer effizienten Art und Weise.\\

\noindent Hinweis:
\begin{align*}	
	\Phi_i(V) & = 
	\begin{bmatrix}
		1	&		&\\
			& \ddots&\\
			&		& 1
	\end{bmatrix}
	\leftarrow \frac{\partial y_i}{\partial V_i}(V)\\
	& = (I + (V\varphi(V)\cdot l_{n+i})\cdot l_{n+i}^T)
\end{align*}

\noindent Effizienz:

$COST(EVAL(F'(x)\cdot \dot{x})) \approx c_1 \cdot COST(EVAL(F(x)))$\\
wobei $c_1$ eine konstante Zahl (typisch $c_1\approx 2-5$) ist.
$\Rightarrow$ Auswertung der Jacobimatrix ergibt $COST(EVAL(F'(x))) = n \cdot c_1 \cdot Cost(EVAL(F(x)))$, da im ungünstigsten Fall $F'(x)\cdot\dot{x}$ für alle $n$ Einheitsrichtungen $l_1,\dots, l_n$ ausgeführt werden muss.\\

\noindent Bemerkung:
\begin{itemize}
	\item Effizienz des Forward Mode entspricht dem Aufwand vom Differenzenquotient
	\item Vorteil: kein \glqq $\tilde{h}$"\ benötigt
	\begin{itemize}
		\item[$\rightarrow$] keine Rundungs-/ Approximationsfehler
		\item[$\rightarrow$] bis auf Rechengenauigkeit exakt\\
		(abhängig von originaler Evaluation Procedure)
	\end{itemize}
\end{itemize}

\noindent Problem:

Für eine große Anzahl von abhängigen Variablen ist das immer noch teuer\\

\noindent $\Rightarrow$ Backward Mode\\
Ziel: effiziente Auswertung von
$$ \bar{y}^T F'(x)$$
mit welcher man z.B. nur einen Aufruf benötigen würde um den gesuchten Gradient $\nabla F \in \mathbb{R}^n$  von $F: \mathbb{R}^n \mapsto \mathbb{R}$ zu berechnen.\\
(setze $\bar{y}=1 \Rightarrow \bar{y}^TF'(x)=1\cdot \nabla F(x)$)\\

\noindent Überlegung: anstatt
$$\dot{y} = \xleftarrow{P \Phi_l'(V_l)\cdot\Phi_{l-1}'(V_{l-1})\cdot\dots\cdot\Phi_1'(V_1)\cdot Q\dot{x}}$$
wie im Foward Mode zu berechnen, muss nun 
$$\bar{x} = \xrightarrow{\bar{y} P \Phi_l'(V_l)\cdot\Phi_{l-1}'(V_{l-1})\cdot\dots\cdot\Phi_1'(V_1)\cdot Q}$$
ausgewertet werden. Dies kann auf zwei Arten geschehen (inkrementell und nicht inkrementell). In beiden Fällen werden die Werte $V_i$ benötigt.\\

\noindent Non-Incremental:
\begin{tabular}{L L c}
	v_{i-n}=x_i						& i = 1,\dots,n &\\
	v_i =\varphi_i(v_j)_{j\prec i}	& i = 1,\dots,l & \glqq Forward Sweep" \\
	y_{m-i} = v_{l-i}				& i = m-1,\dots,0 & zum berechnen der $v_i$'s\\
	\hline
	\bar{v}_{l-i} = \bar{y}_{m-i}	& i={m-1},\dots,0 & \\
	\bar{v}_j = \sum_{i\succ j}\bar{v}_i \frac{\partial}{\partial v_j} \varphi_i(u_i)
									& i=l-m, \dots,1-n & \glqq Backward Sweep"\\
	\bar{x}_i=\bar{v}_{i-n}			& i=n,\dots,1 &für (*)
\end{tabular}

\noindent Incremental:
Foward Sweep:
\begin{tabular}{L L}
	v_i = 0 & i=1-n,\dots,0\\
	\hline
	\bar{v}_{l-i} = \bar{y}_{m-i} & i=0,\dots,m-1\\
	\bar{v}_j += v_i \frac{\partial}{\partial v_j} \varphi_i(u_i) \text{ für } j\prec i & i=l,\dots 1\\
	\bar{x}_i = \bar{v}_{i-n} &i=n,\dots1
\end{tabular}

$\Rightarrow$\\
Auswertung von $\bar{x} = \bar{y}^TF'(x)$ benötigt eine Auswertung von F (Forward Sweep) und einen \glqq Reverse Sweep \grqq. Der Aufwand kann nach oben abgeschätzt werden:
$$OPS(EVAL(\bar{y}^TF'(x))) \approx c_2 OPS(EVAL(F(x)))$$
wobei $c_2$ kleine Konstante ist.\\

\noindent
Beispiel $f(x_1,x_2) = \dots$

\begin{tabular}{L L c}
	\hline
	v_{-1}=x_1				& &\\
	v_0 = x_2				& &\\
	v_1 = v_{-1}^2			& &\\
	v_2 = v_0 \cdot v_1		& &\\
	v_3 = sin(v_{-1})		& & Forward Sweep\\
	v_4 = \frac{v_2}{v_3}	& &\\
	v_5 = cos(v_0)			& &\\
	v_6 = v_4+ v_5			& &\\
	y_1 = v_6				& &\\
	\hline
	\bar{v}_6 = \bar{y}_1													&&\\
	\bar{v}_5 = \bar{v}_6 \frac{\partial}{\partial v_5} (v_4 + v_5) &= \bar{v}_6 \cdot 1	&\\
	\bar{v}_4 = \bar{v}_6 \frac{\partial}{\partial v_4} (v_4 + v_5)&= \bar{v}_6 \cdot 1	&\\
	\bar{v}_3 = \bar{v}_4 \frac{\partial}{\partial v_3} \frac{v_2}{v_3}&= \bar{v}_4 \cdot \frac{-v_2}{v_3^2}&\\
	
	\bar{v}_2 = \bar{v}_4 \frac{\partial}{\partial v_2} \frac{v_2}{v_3}&= \bar{v}_4 \cdot \frac{1}{v_3}&\\
	
	\bar{v}_1 = \bar{v}_2 \frac{\partial}{\partial v_1} (v_0 \cdot v_1)&= \bar{v}_2 \cdot v_0&\\
	\bar{v}_0 = \bar{v}_2 \frac{\partial}{\partial v_0} (v_0 \cdot v_1)+ \bar{v}_5 \frac{\partial}{\partial v_0} cos(v_0) &= \bar{v}_2 \cdot v_1+ \bar{v}_5 \cdot (-sin(v_0)) &\\
	
	\bar{v}_{-1} = \bar{v}_1 \frac{\partial}{\partial v_{-1}} (v_{-1}^2) + \bar{v}_3 \frac{\partial}{\partial v_{-1}} sin(v_{-1}) &= \bar{v}_1 \cdot 2v_{-1} + \bar{v}_3 cos(v_{-1}) &\\
	
	\bar{x}_2 = \bar{v}_0 		&&\\
	\bar{x}_1 = \bar{v}_{-1}	&&\\
	\hline
\end{tabular}
\begin{tabular}{L L L}
	\bar{x}_1 = \bar{v}_{-1} & = \bar{v}_{-1} 2\bar{v}_{-1} &+ \bar{v}_3cos(\bar{v}_{-1})\\
	& = 2 x_1 \c dot \bar{v}_{-1} &+ cos(x_1)\cdot \bar{v}_3\\
	& = 2x_1\bar{v}_2 \cdot v_0 &+ cos(x_1) \cdot \bar{v}_4 \cdot \left(-\frac{v_2}{v_3^2}\right)\\
	& = 2x_1x_2\cdot \bar{v}_2 &+ \frac{-x_1^2\cdot x_2 cos(x_1)}{sin(x_1)^2} \cdot \bar{v}_4\\
	& = \frac{2x_1\cdot x_2\cdot \bar{v}_4}{sin(x_1)} &+ \frac{-x_1^2\cdot x_2 cos(c_1)}{sin(x_1)^2} \cdot 1 \cdot \bar{v}_6\\
	& = \frac{2x_1\cdot x_2\cdot \bar{v}_4}{sin(x_1)}\cdot 1 \cdot \bar{v}_6 &+\ \ -\glqq -\\
	& = \bar{y}_1 \left(\frac{2x_1\cdot x_2 sin(x_1) - x_1^2\cdot x_2 cos(x_1)}{sin^2(x_1)}\right)\\
	\hline
\end{tabular}\\
\begin{tabular}{L L}
	\bar{x}_2 = \bar{v}_0 & = \bar{v}_2 \cdot v_1 + \bar{v}_5 (-sin(v_0))\\
	& = \bar{v}_2 \cdot x_1^2 - sin(x_2) \cdot \bar{v}_5\\
	& = \bar{v}_4 \cdot \frac{1}{sin(x_1)}x_1^2 - sin(x_2)\cdot \bar{v}_6 \cdot 1\\
	& = \bar{v}_0 \cdot 1 \cdot \frac{x_1^2}{sin(x_1)} - sin(x_2)\cdot \bar{y}_1\\
	& = \frac{x_1^2}{sin(x_1)} - sin(x_2)\\
\end{tabular}\\

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}
Zusätzliche evtl. doppelte oder unvollständige Notizen zum Kapitel aus der Vorlesung:\\


ForwardMode: $J \cdot v$ : Jacobi * Vektor

BackwardMode: $v^T \cdot J$: Vektor$^T$ * Jacobi

\noindent Ziel: effiziente Auswertung von $v^TF'(x) = \dot{y}$
Überlegung: $\dot{y} = P \Phi'_l(V_l)\cdot \Phi'_{l-1}(V_{l-1})\dots \Phi'_1(V_1)\cdot Q \cdot \dot{x}$

wie um Forward Mode zu berechnen muss nun

$\dot{x} = \bar{y}^TP\Phi'_l(V_l)\dots \Phi'_1(V_1)\cdot Q$
ausgewertet werden

Non-Incremental:

\begin{tabular}{| L L |}
	v_{i-n} = x &i=1\dots n\\
	v_i=\varphi_i(v_j)_{j\prec i} &i=1 \dots l\\
	y_{m-i} = v_{l-i} & i=m-1 \dots 0\\
	\hline
	\bar{y}^TP\bar{v}_{l-i} = \bar{y}_{m-l}& i =m-1 \dots 0\\
	\bar{v}^T\Phi'(\dots)\bar{v}_j = \sum_{i\succ j} \bar{v}_j&\\
	&\\
\end{tabular}

Incremental: (Zusatzmaterial)

\begin{tabular}{| L L |}
	v_{i-n} = x &i=1\dots n\\
	v_i=\varphi_i(v_j)_{j\prec i} &i=1 \dots l\\
	y_{m-i} = v_{l-i} & i=m-1 \dots 0\\
	\hline
	\bar{v}_i = 0 & i =1-n \dots l\\
	\bar{v}_{l-1} = &\\
	\bar{v}^T\Phi'(\dots)\bar{v}_j = \sum_{i\succ j} \bar{v}_j&\\
	&\\
\end{tabular}


$\rightarrow$ Auswertung von $\bar{x} = \bar{y}^TF'(x)$ benötigt eine Auswertung von F (Forward-Sweep) und einen Reverse Sweep. Der Aufwand kann nach oben abgeschätzt werden

$$OPS(EVAL(\bar{y}^TF'(x))) \leq c_2 OPS(EVAL(F(k)))$$,
wobei $c_2$ eine Konstante ist $(c_2\approx 2-5)$
\\
Fehler bisher, sollte sein: (inkorrekte Korrektur, unvollständig)
$$\bar{v}_i \sum_{i\succ j} \bar{v}_i \frac{\partial}{\partial v_j}\varphi_i(u_i)$$


Bsp. Reverse Sweep (Non-Incremental) $f(x_1,x_2)$
wir wollen berechnen $\bar{y}^Tf'(x), f: \mathbb{R}^2\mapsto\mathbb{R}^1$

\begin{tabular}{| L  L |}
	\bar{y}_1 = 1 &\\
	\bar{v}_6 = \bar{y}_1 &\\
	\bar{v}_5 = \bar{v}_6 \frac{\partial}{\partial v_5}(v_4+v_5) & = \bar{v}\cdot 1\\
	\bar{v}_4 = \bar{v}_6 \frac{\partial}{\partial v_4}(v_4+v_5)& = \bar{v}\cdot 1\\
	\bar{v}_3 = \bar{v}_4 \frac{\partial}{\partial v_3}(\frac{v_2}{v_3})&  = \bar{v}_4 \cdot \left( -\frac{v_2}{v_3^2}\right)\\
	\bar{v}_2 = \bar{v}_4 \frac{\partial}{\partial v_2}(\frac{v_2}{v_3})&) =\bar{v}_4 \cdot \left(\frac{1}{v_3}\right)\\
	\bar{v}_1 = \bar{v}_2 \frac{\partial}{\partial v_1}(v_0 \cdot v_1) & =\bar{v}_2 \cdot v_0\\
	\bar{v}_0 = \bar{v}_2 \frac{\partial}{\partial v_0}(v_0 \cdot v_1) + \bar{v}_5 \frac{\partial}{\partial v_0}(cos(v_0))& =  =\bar{v}_2 \cdot v_1 + \bar{v}_5(-sin(v_0))\\
	\bar{v}_{-1} = \bar{v}_2 \frac{\partial}{\partial v_0}(v_0 \cdot v_1) + \bar{v}_5 \frac{\partial}{\partial v_0}(cos(v_0))& =2 \bar{v}_1 v_{-1} + \bar{v}_3 cos(v_{-1})\\
	%	\hline
\end{tabular}

\vspace{\baselineskip}
Aufgaben:
\begin{itemize}
	\item Fehler von \ref{subsec:numerisch / Differenzenquotient} nachimplementieren
	\item Forward Mode implementieren
	\item Rosenbrock
\end{itemize}

Datentyp adouble erstellen, der 2 Werte speichert: einen für den Wert selbst und eines für die Richtung -> wichtiger Teil Fkt. a la operator+ 

in Matlab: Adimat (Uni Darmstadt)