\section{Dünnbesetzte Ableitungsmatrizen}
\label{chap:sparsemats}

Gegeben sei eine Funktion $F:\mathbb{R}^n\mapsto\mathbb{R}^m$ deren Jacobi-Matrix $F'(x) \in \mathbb{R}^{m\times n}$ dünnbesetzt ist, d.h. nur wenige Nichtnulleinträge besitzt. Das Ziel ist nun diese Einträge (und somit die Jacobi-Matrix) effizient zu bestimmen.

\noindent
Für den allgemeinen Fall haben wir gesehen, dass der FM eine effiziente Methode bietet $F'(x)\cdot s$ auszuwerten.

\noindent
Somit war es möglich $F'(x)$ durch eine geeignete Wahl von Richtungen  $s_1,\dots$ auszuwerten, z.B. mit den Einheitsvektoren $e_1,e_2, \dots e_n$, lieferte uns $F'(x)$ spaltenweise.\\


\begin{itemize}
	\item[Ziel:] Bestimmung von $F'(x)$ mit $p <<n$ FM Auswertungen
	\item[Frage:]Wie groß ist $p$ und wie sind die Richtungen $S_1,\dots S_p$ zu wählen?
	\item[Bem.:] Die Matrix $S = [S_1, \dots S_p] \in \mathbb{R}^{n\times p}$ wird oft als \glqq Seed\grqq Matrix genannt und ist im Folgenden hilfreich.
	\item[Bsp.:]
	Mit $S$ lässt sich die Auswertung des FM mit den $p$ Richtungen kurz als 
	$$B = F'(x)S$$
	darstellen, wobei die Zeilen $b_i^T$ von $B$ durch $b_i^T = \nabla F_i(x)^TS$ gegeben sind.
\end{itemize}

\noindent
M.A.W. wie ist $S\in\mathbb{R}^{n\times p}$ zu wählen, damit $B$ alle Informationen über $F'(x)$ enthält, so dass man diese auch zurückberechnen kann?\\

\noindent
Beispiel Matrixgrafik mit Sparsity pattern\\
\vspace{3cm}

\noindent
genauer, wann lassen sich alle GLS $b_i^T = w_i^TS$ eindeutig nach $w_i (=\nabla F_i(x))$ auflösen?\\
$\Rightarrow$ es werden mindestens genau so viele Gleichungen wie Unbekannte benötigt\\

\noindent
d.h. $p \geq p_i$, wobei $p_i$ die Anzahl der Nichtnulleinträge der $i$-ten Zeile von $F'(x)$ ist. Die Indexmenge dieser Nichtnulleinträge wird mit $\chi_i$ bezeichnet
$$\Rightarrow b_i^T = e_i^T A \cdot S = \sum_{j=1}^n e_i^T A e_j e_j^T S =\sum_{j\in \chi_i} e_i^T A e_j (e_j^T S) = a_i^T S_i \ ,\ \ \ \ A \leftarrow F'(x)$$
$$\Rightarrow S_i^Ta_i = b_i\text{ mit }S_i = (e_j^TS)_{j\in X_i^{\in \mathbb{R}^{p_i\times p}}}$$
vermeintliches LGS zur Bestimmung der Nichtnulleinträge.\marginpar {Formulierung}\\
$S_i$ kann so partitioniert werden, dass $S_i = [\tilde{S}_i,\dots,\tilde{S}_i]^{\in \mathbb{R}^{p_i\times p}}$ mit $Det(S_i) \neq 0$.\\
$\Rightarrow$ Quadratisches LGS
$$\tilde{S}_i^Ta_i = \tilde{b}_i=\left(e_k^Tb_i\right)_{k=1,\dots,p_i}$$
mit $p_i$ Gleichungen und $p_i$ Unbekannten.\\

\noindent
Herausforderung: Lösen von $m$ kleinen LGS zur Bestimmung von allen Zeilen von $F'(x)$\\

\noindent
$\Rightarrow$ geht auch ohne Lösen von LGS über Graph Coloring.

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}
\subsection{Vertretungsvorlesung zu Sparse Matrices}
\label{subsec:vertretungsvorlesung}
\input{chaps/chap5_vertr}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}
ab hier weiter mit regulärer VL

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\noindent
\underline{Wiederholung:}
\begin{itemize}
	\item[Ziel:] effiziente Berechnung von dünnbesetzten Abhleitungen $F'(x)$, deren dünnbesetzte Struktur bekannt ist.
	\item[$\rightarrow$]  Ausnutzen des FM bzw. RM, d.h. finde geeignete\\ Seedmatrix (Richtungen)
	$$S = S_1, \dots , S_p \in \mathbb{R}^{n\times p}$$
	so dass
	$$B=F'(x) \cdot S$$
	alle Informationen von $F'(x)$ enthält.
	
\end{itemize}

\subsection{Curtis-Powell-Reid Seeding}
\label{subsubsec:CPRseeding}
Durch Coloring/ Färbung des Spaltenzshgs.graphen $G=(V,E)$ von $F'(x)$ bestehend aus
\begin{itemize}
	\item Knoten $V=\{1\dots n\}$, die je einer Spalte von $F'(x)$ entsprechen und 
	\item Kanten $E\subseteq V\times V$, die durch wiederholt auftretende Einträge in den Spalten induziert werden
\end{itemize}
M.A.W. es existiert eine Kante $(i,j)$ zwischen Knoten $i$ und $j$ $\Leftrightarrow$ Spalte $i$ und $j$ von $F'(x)$ haben mindestens einen gemeinsamen Nichtnulleintrag.\\

\begin{tabular}{l}
	$\begin{bmatrix}
	*	& *	& *	& *	& 0	& 0	& 0	& 0	& 0	& 0\\
	*	& *	& 0	& 0	& *	& *	& 0	& 0	& 0	& 0\\
	*	& *	& 0	& 0	& 0	& 0	& *	& *	& 0	& 0\\
	0	& 0	& *	& *	& *	& *	& 0	& 0	& 0	& 0\\
	0	& 0	& *	& *	& 0	& 0	& * & *	& 0	& 0\\
	0	& 0	& *	& *	& 0	& 0	& 0 & 0	& *	& *\\
	\end{bmatrix}$
	\begin{tabular}{l}
		$\rightarrow$ \underline{Übung:}\\
		$\cdot$ Spalten-/ Zeilenzsghs.graphen erstellen\\
		$\cdot$ (optimales) Coloring\\
		$\cdot$ Seed Matrix\\
		$\cdot$ Compressed Jacobial\\
	\end{tabular}
\end{tabular}\\


Beispiel: $*$ -Nichtnulleintrag, $0$ - Null\\
$A=\begin{bmatrix}
*	& *	& 0	& 0	\\
*	& 0	& *	& 0	\\
*	& 0	& 0	& *	\\
0	& 0	& *	& *	\\
\end{bmatrix}
=
\begin{bmatrix}
a_{11}	& a_{12}	& 0	& 0	\\
a_{21}	& 0	& a_{23}	& 0	\\
a_{31}	& 0	& 0	& a_{34}	\\
0	& 0	& a_{43}	& a_{44}	\\
\end{bmatrix}
$\\


Spaltenzusammenhangsgraph:
$$V=\{1,2,3,4\},\ \ E=\{(1,2),(1,3),(1,4),(3,4)\}$$

Zeilenzusammenhangsgraph (analog definiert):
$$V=\{1,2,3,4\},\ \ E=\{(1,2),(1,3),(2,3),(2,4),(3,4)\}$$

\noindent
\subsubsection{Spaltenkompression}
Färbung des Spaltenzshgs.graphen
\label{subsubsec:coloring_col_intersection_graph}

$$c:\{1\dots n\}\mapsto \{1\dots p\}$$
mit (möglichst wenig) $p$ Farben (1-Rot, 2-Grün, 3-Blau, 4-Gelb,\dots)
liefert die entsprechende Seedmatrix: ($e_k$ bezeichnet den $k$-ten kartesischen Basisvektor)
$$S = [e^T_{c(j)}]_{j=1,\dots,n}\in \mathbb{R}^{n\times p}\ \ \ e_k^T = [0 \dots 0,1_k, 0 \dots 0]$$
und die Anzahl der notwendigen Richtungen $p$ (d.h. nötige Aufrufe des FM).\\

\noindent
Grafik:\\3 mal Spaltenzusammenhangsgraph nebeneinander, verschiedene Colorings\\
4 Farben [1: Rot(1), Grün(2) , Blau(3),Gelb(4)]\marginpar{Hier anders als in VL!}\\
3 Farben [2: Rot(1), Grün(2,4),Blau(3)]\\
3 Farben [3: Rot(1), Grün(2,3),Blau(4)]\\
\vspace{3cm}
\\
\begin{tabular}{c c c}
	$S^I = \begin{bmatrix}
	1	& 0	& 0	& 0	\\
	0	& 1	& 0	& 0	\\
	0	& 0	& 1	& 0	\\
	0	& 0	& 0 & 1	\\
	\end{bmatrix}_{4\times 4}$
	&
	$S^{II} = \begin{bmatrix}
	1	& 0	& 0	\\
	0	& 1	& 0	\\
	0	& 0	& 1	\\
	0	& 1	& 0	\\
	\end{bmatrix}_{3\times 4}$
	&
	$S^{III} = \begin{bmatrix}
	1	& 0	& 0	\\
	0	& 1	& 0	\\
	0	& 1	& 0	\\
	0	& 0	& 1	\\
	\end{bmatrix}_{3\times 4}$\\
	
	
	
	$AS^I =
	\begin{bmatrix}
	a_{11}	& a_{12}	& 0	& 0	\\
	a_{21}	& 0	& a_{23}	& 0	\\
	a_{31}	& 0	& 0	& a_{34}	\\
	0	& 0	& a_{43}	& a_{44}\\
	\end{bmatrix}$
	&
	$AS^{II}=
	\begin{bmatrix}
	a_{11}	& a_{12}& 0		\\
	a_{21}	& 0		& a_{23}\\
	a_{31}	& a_{34}& 0		\\
	0		& a_{44}& a_{43}\\
	\end{bmatrix}$
	&
	$AS^{III}=
	\begin{bmatrix}
	a_{11}	& a_{12}& 0		\\
	a_{21}	& a_{23}& 0		\\
	a_{31}	& 0		& a_{34}\\
	0		& a_{43}& a_{44}\\
	\end{bmatrix}$
\end{tabular}\\

\noindent
\underline{Problem:}\\
Rekonstruktion von $A (=F'(x))$ aus $B=A\cdot S$\\
$\Rightarrow$ Lsg von $b_i^T = w_i^TS_i$ bzgl. $w_i^T$ liefert die $p_i$ Nichtnulleinträge von $\nabla F_i(x)$\\
Beispielgrafik der Matrixberechnung\\
\vspace{3cm}


$$\Rightarrow\ b_i^T =w_i^TS_i = e_i A S = e_i \sum_{j \in X_i} Ae_j^{}e_j^TS$$
wobei  $\chi_i$ das Sparsitypattern der $i$-ten Zeile von $F'(x)$ ist, d.h. die Indizes der Nichtnulleinträge von $v\cdot F_i'(x)$\\
$\Rightarrow\ b_i^T =w_i^TS_i \Leftrightarrow S_i^Tw_i = b_i$ ist ein überstimmtes LGS!\\

\marginpar{Korrektheit/ Vollständigkeit/ Verständlichkeit überprüfen}
\begin{itemize}
	\item[$\Rightarrow$] Löse stattdessen $\tilde{S}_i^Tw_i = \tilde{b}_i$
	mit
	$\tilde{S}_i \in \mathbb{R}^{p_i\times p_i}$
	und
	$S_i = \begin{Bmatrix}
	\tilde{S}_i & \dots & \tilde{S}_i\end{Bmatrix}_{p_i \times p_i}$ und  $S_i= (e_jS)_{j \in x_i}$
	und
	$Det(\tilde{S}_i)\neq 0$, $\tilde{b}_i = (e_k+b_i)_{k=1,\dots p_i}$\\
	( wobei
	$e_k$ die zu $\tilde{S_i}$ entsprechenden Spaltenindizes sind )\\
	
	\item[$\Rightarrow$] Im Fall von CPR (Curtis-Powell-Reid) ist\\
	$$S_i = \left[l^T_{c(j)}\right]_{j\in \chi_i}\in \mathbb{R}^{p_i\times p},\ \ \ \chi_i \hat{=} \text{ Sparsitypattern von Zeile } i$$
	gegeben als permutierte Einheitsmatrix mit angehängter Nullmatrix.
\end{itemize}
\newpage
\noindent
Beispiel zur Matrix\\
$A=\begin{bmatrix}
a_{11}	& a_{12}	& 0	& 0	\\
a_{21}	& 0	& a_{23}	& 0	\\
a_{31}	& 0	& 0	& a_{34}	\\
0	& 0	& a_{43}	& a_{44}\\
\end{bmatrix}$:
\begin{tabular}{l}
	Sparsity-Pattern:\\
	für $i$ Zeilen, jeweils die Indexmenge der Nichtnulleinträge:
\end{tabular}\\
\begin{tabular}{L}
	x_1 = \{1,2\}\\
	x_2 = \{1,3\}\\
	x_3 = \{1,4\}\\
	x_4 = \{3,4\}\\
\end{tabular}
$S^{II} = \begin{bmatrix}
1	& 0	& 0	\\
0	& 1	& 0	\\
0	& 0	& 1	\\
0	& 1	& 0	\\
\end{bmatrix}
$
\begin{tabular} { l | l}
	$S_1^{II} = \begin{bmatrix}
		e_{C(1)}^T\\
		e_{C(2)}^T
	\end{bmatrix}= \begin{bmatrix}
		1	& 0	& 0	\\
		0	& 1	& 0	\\
	\end{bmatrix}$
	&
	$\tilde{S}_1^{II}=\begin{pmatrix}
	1	& 0\\
	0	& 1\\
	\end{pmatrix}$
	\\
	$b_1 = (a_{11}, a_{12},0)$ & $\tilde{b}_1 = (a_{11},a_{12})$
	\\
	\hline
	$S_2^{II} = \begin{bmatrix}
	e_{C(1)}^T\\
	e_{C(3)}^T
	\end{bmatrix} = \begin{bmatrix}
	1	& 0	& 0	\\
	0	& 0	& 1	\\
	\end{bmatrix}$
	&
	$\tilde{S}_2^{II} = \begin{pmatrix}
	1&0\\
	0&1\\
	\end{pmatrix}$
	\\
	$b_2 = (a_{21}, 0, a_{23})$&$\tilde{b}_2 = (a_{21},a_{23})$
	\\
	\hline
	$S_3^{II} = \begin{bmatrix}
	e_{C(1)}^T\\
	e_{C(4)}^T
	\end{bmatrix} = \begin{bmatrix}
	1	& 0	& 0	\\
	0	& 1	& 0	\\
	\end{bmatrix}$
	&
	$\tilde{S}_3^{II} = \begin{pmatrix}
	1&0\\
	0&1\\
	\end{pmatrix}$
	\\
	$b_3 = (a_{31}, a_{34},0)$&$\tilde{b}_3 = (a_{31},a_{34})$
	\\
	\hline
	$S_4^{II} = \begin{bmatrix}
	e_{C(3)}^T\\
	e_{C(4)}^T
	\end{bmatrix} = \begin{bmatrix}
	0	& 0	& 1	\\
	0	& 1	& 0	\\
	\end{bmatrix}$
	&	
	$\tilde{S}_4^{II} = \begin{pmatrix}
	1&0\\
	0&1\\
	\end{pmatrix}$\\
	$b_4 = (0,a_{44}, a_{43})$&$\tilde{b}_4 = (a_{44},a_{43})$\\	
\end{tabular}

$\Rightarrow$ Lsg. von $\tilde{S}_i^Tw_i=\tilde{b}_i$,$i=1\dots n$ liefert Nichtnulleinträge $w_i$ von \\

\begin{tabular}{l l}
	\begin{tabular}{l}
		$\begin{pmatrix}
		1 & 0\\
		0 & 1\\
		\end{pmatrix}\begin{pmatrix}
		w_{11}\\
		w_{12}\\
		\end{pmatrix} = \begin{pmatrix}
		a_{11}\\
		a_{12}\\
		\end{pmatrix}$\\
		$\begin{pmatrix}
		1 & 0\\
		0 & 1\\
		\end{pmatrix}\begin{pmatrix}
		w_{21}\\
		w_{22}\\
		\end{pmatrix} = \begin{pmatrix}
		a_{21}\\
		a_{23}\\
		\end{pmatrix}$\\
		$\begin{pmatrix}
		1 & 0\\
		0 & 1\\
		\end{pmatrix}\begin{pmatrix}
		w_{31}\\
		w_{32}\\
		\end{pmatrix} = \begin{pmatrix}
		a_{31}\\
		a_{34}\\
		\end{pmatrix}$\\
		$\begin{pmatrix}
		1 & 0\\
		0 & 1\\
		\end{pmatrix}\begin{pmatrix}
		w_{41}\\
		w_{42}\\
		\end{pmatrix} = \begin{pmatrix}
		a_{44}\\
		a_{43}\\
		\end{pmatrix}$\\
	\end{tabular}
	&
	$A=\begin{bmatrix}
	w_{11}	& w_{12}	& 0	& 0	\\
	w_{21}	& 0	& w_{22}	& 0	\\
	w_{31}	& 0	& 0	& w_{32}	\\
	0	& 0	& w_{41}	& w_{42}\\
	\end{bmatrix}$
\end{tabular}\\

\subsubsection{Zeilenkompression}
\label{subsubsec:row_compr}
Analog zur Spaltenkompression von rechts mittels des FM ($F'(x)\cdot S)$ kann auch von links mittels des RM ($S\cdot F'(x)$) komprimiert werden mit dem Zeilenzshgs.graph.\\

\noindent
M.A.W. betrachte nun  \marginpar{Dimensionen evtl. falsch}
$$ C^T = W^T F'(x) \in \mathbb{R}^{q\times n}$$
wobei $W^T \in \mathbb{R}^{m\times q}$ nun die adjugierte Seed Matrix ist und $c^T \in \mathbb{R}^{q \times n}$ die komprimierte Darstellung der Jacobimatrix ist.\\

\noindent
\subsubsection{Zeilen- \& Spaltenkompression gleichzeitig}
\label{subsubsec:r_c_compr}
typisches Gegenbeispiel:

$\begin{bmatrix}
* & \dots & * \\
\vdots & \ddots & 0\\
*	&	0	& *\\
\end{bmatrix} \Rightarrow$
\begin{tabular}{l}
	hier funktioniert weder\\
	Zeilen- noch Spalten-\\
	kompression alleine
\end{tabular} 

$F'(x) \cdot \begin{pmatrix}
0 &1\\1&0\\ \vdots&0\\1&0
\end{pmatrix}
\begin{pmatrix}
1 & 0 & \dots &0
\end{pmatrix}
\cdot F'(x)$
$\Rightarrow$ \begin{tabular}{l}bei dieser Zerlegung würde\\es wieder funktionieren\end{tabular}\\

\noindent
$\Rightarrow$ \underline{Beidseitige Kompression}, d.h. finde $S$ und $W$ für Kompressionsmatrix\\
$$B=A\cdot S \text{ und } C=A^TW\text{,}$$\\
die genügend Informationen enthält um die Nichtnulleinträge von $F'(x)$ wieder herzuleiten.

\subsubsection{Coleman und Verma}
\label{subsubsec:part_row/column_compr}

\begin{itemize}
	\item[Idee:] Partitionierung von A in Blöcke, z.B. wie folgt\\
	Grafik: Matrix A in Blöcke aufgeteilt\\
	(r- row compression, c - column compression)\\
	\vspace{2cm}
	
	$A=$\hspace{6cm}$=A^r+A^c$
	\vspace{2cm}
\end{itemize}
\begin{itemize}
	\item[$\Rightarrow$] Bestimme Seed $S \in \mathbb{R}^{n\times p}$ für $A^r$ und Seed $W^T \in \mathbb{R}^{q\times m}$ für $A^c$.\\
	
	Entsprechend gilt:
\end{itemize}
$$B=AS = A^rS + A^cS$$
$$C = A^TW = (A^r)^TW + (A^c)^TW$$

Die Blöcke $A_i^R$ und $A_j^c$ können nacheinander ausgehend von $A_1^r$ bestimmt werden,\\
M.A.W. die letzten Zeilen von $B=A\cdot S$ hängen nur von $A^r$ ab und können mit Standard Spaltenkompression ermittelt werden.

Das Ergebnis kann benutzt werden um $C$ zu korrigieren.
$$\dot{C} = C- (\bar{A}_1^r)^TW \text{ bzw. }A^TW = A^TW- (\bar{A}_1^r)^TW\text{,}$$
wobei\marginpar{Formel korrekt?}
$$\bar{A}_1^r = \left[\frac{0}{A_1^r}\right] \in \mathbb{R}^{DIM(A)}$$
Dann kann $A_1^c$ (mit Standard Zeilenkompression )zurückberechnet werden. usw.

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

Wichtig in diesem Kapitel:
\begin{itemize}
	\item Sparse Matrizen mit Nichtnulleinträgen,
	\item wiederberechnen mit möglichst wenig Vektoren+ zurückrechnen (über Zeilen/Spaltenzshgsgraphen+Coloring)
	\item Weg zur Rückberechnung welcher Wert im aktuellen Eintrag steht
	\item \dots
\end{itemize}