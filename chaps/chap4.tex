\section{Checkpointing}
\label{chap:Checkpointing}

\underline{Wiederholung}
Beim Vorwärtsmodus ($F'(x)\cdot s$) und Rückwärtsmodus ($s^TF'(x)$) hatten wir gesehen, dass für $F:\mathbb{R}^n\mapsto\mathbb{R}^n$ folgende Abschätzungen gelten.

\begin{tabular}{LL}
	OPS(EVAL(F'(x)\cdot s)) &\le c_1 \cdot OPS()Eval(F(x))\\
	OPS(EVAL(s^T\cdot F'(x))) &\le c_2 \cdot OPS()Eval(F(x))
\end{tabular}\\
und somit

\begin{tabular}{L}
	OPS(EVAL(F'(x))) \le MIN(n,m) OPS(EVAL(F(x))
\end{tabular}\\
insbesondere

\begin{tabular}{L}
	OPS(EVAL(vf(x))) \le c OPS(EVAL(f(x)))
\end{tabular}\\
für $f:\mathbb{R}^n\mapsto \mathbb{R}^n$ im Gegensatz zu FD, wo $n+1$ Auswertungen von $f$ benötigt werden.\\

\noindent
\underline{Wichtig:}
Die Abschätzungen gelten nur für die Anzahl der Operationen!!!

\noindent Rechenoperationen sind meist billig im Vergleich zu Lese-/Schreibzugriffen auf fast allen Systemen.\\

\noindent
\underline{Forward/ Reverse Mode und Speicherbedarf}\\

Forward Mode $\dot{y} = F'(x)\dot{x}$ : 
\begin{tabular}{L L L }
	v_{i-n} & = x_i& i = 1\dots n\\
	\dot{v}_{i-n} &= \dot{x}_i&\\
	\hline
	v_i &=\varphi (v_j)_{j\prec i}&i=1\dots l\\
	\dot{v}_i &= \sum_{j\prec i} \frac{\partial}{\partial v_j} \varphi_i<(u_i)\dot{v}_j&\\
	\hline
	y_{m-i} &=v_{l-i}&i= (m-1) \dots 0\\
	\dot{y}_{m-i} &= \dot{v}_{l-i}&\\
	\dot{y} &= \varPhi \ \ \ \ \ \ \varPhi \dot{x}&
\end{tabular}
$\rightarrow \dot{v}$ wird nur so lange benötigt, wie $v$ benötigt wird, kann also während der Laufzeit schon gelöscht werden. Mit anderen Worten der Speicheraufwand für den Forward-Mode entspricht in etwa dem Speicheraufwand der Funktionsauswertung (bis auf konstanten Faktor).

$\rightarrow$ Forward Mode stellt kein Problem dar\\
anders sieht es im Backward Mode aus:\\
$\bar{x}=\bar{y}F'(x)$
\begin{tabular}{L L}
	v_{i-n}=\dot{x}_i & i = 1-n,\dots,l\\
	v_i = \varphi( )  & i= 1, \dots, l\\
	y_{m-i} = v_{l-i} & i=m-1, \dots, 0\\
	\hline
	\bar{v}_{l-i}= \bar{y}_{m-i} & i = 0,\dots, m-1\\
	\bar{v}_i = \sum_{i\succ j}\bar{v}_i\frac{\partial}{\partial v_j} \varphi_i(u_i) & i = l,\dots,1\\
	\bar{x}_i = \bar{v}_{i-n} & i=n,\dots,1
\end{tabular}
$$\bar{x}=\bar{y} \varPhi(\ ) \dots \varPhi(\ )$$










\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}
Zusätzliche evtl. doppelte oder unvollständige Notizen zum Kapitel aus der Vorlesung:\\

Wdh. Checkpointing\\
Gegeben $F = F_v \odot F_{v-1} \odot \dots \odot F_1$ D.H.
$x_0 = x \rightarrow x_1 = F_1(x_0) \rightarrow x_2 = F_2(x_1) \rightarrow \dots \rightarrow y= x_v = F_v(x_{v-1})$

Problem: bei Rückwärtssweep müssen alle Werte $x_i$ vorhanden sein (gespeichert werden)

$\bar{x}= \bar{y}^TF'(x) | \bar{x} = \bar{y}_1F'(x_0)  \leftarrow \dots \leftarrow $

Lösung: Checkpoints (CP) - anstatt aller $x_i$  werden nur ausgewählte Werte $x_i$ gespeichert, fehlende werden neuberechnet basierend auf diesen CP

Bsp:

\begin{tabular}{ L L L}
	\text{Startwert} & \text{CP-werte} & \text{Zielwert}\\
	0 \rightarrow & 1 \rightarrow 2 \rightarrow \dots \rightarrow 9 \rightarrow & 10 \\	
\end{tabular}

Vorgehen: Init 0


\begin{tabular} { c L L L }
	Eval + Save & & & \\
	CP : & 0 \rightarrow & 1 \rightarrow 2 \rightarrow \dots \rightarrow 9 \rightarrow & 10 \\
	& \downarrow & \dots \downarrow \dots \downarrow \dots & \\
	Eval + Rev & 9 \rightleftarrows 10 & & \\
	&  \downarrow & & \\
	Load CP+ Eval & 7 \rightarrow 8 & &\\
	Eval + Rev & 8 \rightarrow 9 & &\\
	&  \downarrow & & \\
	Load CP+ Eval & 7 \rightleftarrows 8 & &\\
	
	letzte beiden Load CP + (Eval) + Rev & & &\\
\end{tabular}

Frage: wie werden die Checkpoints verteilt?
$\rightarrow$ Faustregel: kann als dynamisches Optimierungsproblem definiert werden \glqq$MIN t(L,C)$\grqq, wobei 
$$t(l,C) = MIN_{1\leq \tilde{l}\leq} \{\tilde{l} + t( l- \tilde{l},c-1)+t(\tilde{l},c)\}$$
mit
$ t(l,c) \approx$ Zeit für RV von $l$ Teilfkt mit C Checkpoints\\

\vspace{1cm}

Grafik\\

\noindent
Optimierungsproblem hat explizite Form \marginpar{nicht Prüfungsrelevant}
$$t(l,c) = v(l,c) \cdot l - \beta (c+1, r-1)$$
wobei $\beta(c,r) = \frac{(c+v)!}{c!r!}$ und $r = r(l,c)$
die eindeutige natürliche Zahl mit $\beta (c,r-1) < l \leq \beta (c,r)$

(r $\approx$ Ganzzahliges Verhältnis von Kosten für Reversal von l Funktionen mit c Checkpoints zu den Kosten für eine Vorwärtsauswertung)

Prop 12.3 \glqq Bin. Rev. Schedule \grqq\\
die optimalen CP sind gegeben durch 
$$ l(c,r) = \beta(c,r) = \binom{c+v}{c} = \frac{(c+r)!}{c!r!}$$

Faustregel:
\begin{itemize}
	
	\item CP ungefähr bei Hälfte des verbliebenen Abschnitts setzen
	
	Grafik
	\item wenn viele CP vorhanden (im Vgl. zu Rel. Auswertungsaufwand), dann CP eher link von der Mitte
	
	Grafik
	\item ansonsten eher rechts
	
	Grafik
\end{itemize}
